{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import mlflow\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train set as a pandas dataframe\n",
    "train_set = pd.read_csv('data/train_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the features that we are going to use\n",
    "X = train_set.drop(['Churn'], axis=1)\n",
    "y = train_set['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. make pipelines to do the necessary transformations\n",
    "\n",
    "# 1.1 divide the qualitative and quantitative features\n",
    "quantitative_columns = selector(dtype_exclude=['object'])\n",
    "qualitative_columns = selector(dtype_include=['object'])\n",
    "\n",
    "quantitative_columns = quantitative_columns(X)\n",
    "qualitative_columns = qualitative_columns(X)\n",
    "\n",
    "# 1.2 apply the respective transformations with columntransformer method\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(drop='first'), qualitative_columns)],\n",
    "     remainder='passthrough')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up MLFlow Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/4YouSee/Desktop/personal_work/Customer_Churn/mlruns/750646704189071249', creation_time=1672789451297, experiment_id='750646704189071249', last_update_time=1672789451297, lifecycle_stage='active', name='01_churn_customers', tags={}>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up the mlflow experiment\n",
    "experiment_path = 'mlflow_experiments' # Defining the path of experiments in MLFlow\n",
    "experiment_name = '01_churn_customers' # Defining the experiment name in MLFlow\n",
    "\n",
    "if(not(mlflow.get_experiment_by_name(experiment_name))): # If the experiment does not exist, create it\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "    \n",
    "mlflow.set_experiment(experiment_name) # Set the current experiment to register in MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting current date to save\n",
    "year = str(datetime.today().year)\n",
    "month = str(datetime.today().month)\n",
    "if len(month) == 1:\n",
    "    month = \"0\" + month\n",
    "day = str(datetime.today().day)\n",
    "if len(day) == 1:\n",
    "    day = \"0\" + day\n",
    "date = year + \"/\" + month + \"/\" + day "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifier_models(X, y, cv, scoring):\n",
    "    '''Função que treina os seguintes modelos de machine learning:\n",
    "    RandomForestClassifier, DecisionTreeClassifier, SGDClassifier, SVC,\n",
    "    LGBMClassifier, GaussianNB.\n",
    "    A função aplica a validação cruzada no conjunto de dados e retorna a média\n",
    "    da métrica selecionada no conjunto de treino e validação.\n",
    "    As únicas métricas ativas são Acurácia e F1 score.\n",
    "    Os experimentos com os modelos são acompanhados pelo MLflow.\n",
    "    \n",
    "    :param X: (dataframe or numpy array) \n",
    "    Dataframe ou array com o conjunto de variáveis independentes.\n",
    "    \n",
    "    :param y: (series or numpy array)\n",
    "    Coluna ou array com a variável dependente.\n",
    "    \n",
    "    :param cv: (int)\n",
    "    Determina a estratégia de divisão de validação cruzada.\n",
    "    \n",
    "    :param scoring: (str)\n",
    "    Estratégia para avaliar o desempenho do modelo de validação cruzada no conjunto de validação.\n",
    "    Deve ser passada entre aspas ao chamar a função.\n",
    "    '''\n",
    "    # 1. Instantiate the models\n",
    "    rf = RandomForestClassifier()\n",
    "    dt = DecisionTreeClassifier()\n",
    "    sgdc = SGDClassifier()\n",
    "    svc = SVC()\n",
    "    lgbm = LGBMClassifier()\n",
    "    gnb = GaussianNB()\n",
    "\n",
    "    # 2. train and evaluate the models\n",
    "    for model in (rf, dt, sgdc, svc, lgbm, gnb):\n",
    "        pipe = Pipeline(\n",
    "            steps=[('preprocessor', preprocessor),\n",
    "                   ('scaling', StandardScaler()),\n",
    "                   ('classifier', model)\n",
    "                  ]\n",
    "                )\n",
    "        scores = cross_validate(pipe, X, y, return_train_score=True,\n",
    "                                scoring=scoring, cv=cv)\n",
    "\n",
    "        # train and validation with accuracy\n",
    "        if scoring == 'accuracy':\n",
    "            log_train_acc = np.mean(scores['train_score'])\n",
    "            log_test_acc = np.mean(scores['test_score'])\n",
    "\n",
    "            # track the experiment with accuraccy\n",
    "            mlflow.start_run(run_name = date) \n",
    "            mlflow.log_param('Date', date) \n",
    "            mlflow.log_param('Features', X.columns)\n",
    "            mlflow.log_param('Pre-processing', preprocessor) \n",
    "            mlflow.log_param('ML model', pipe[2])\n",
    "\n",
    "            mlflow.log_metric('Train_acc', log_train_acc)\n",
    "            mlflow.log_metric('Test_acc', log_test_acc)\n",
    "\n",
    "            mlflow.end_run()\n",
    "\n",
    "        # train and validation with f1\n",
    "        if scoring == 'f1':\n",
    "            log_train_f1 = np.mean(scores['train_score'])\n",
    "            log_test_f1 = np.mean(scores['test_score'])\n",
    "\n",
    "            # track the experiment with f1 score\n",
    "            mlflow.start_run(run_name = date) \n",
    "            mlflow.log_param('Date', date) \n",
    "            mlflow.log_param('Features', X.columns)\n",
    "            mlflow.log_param('Pre-processing', preprocessor) \n",
    "            mlflow.log_param('ML model', pipe[2])\n",
    "\n",
    "            mlflow.log_metric('Train_f1', log_train_f1)\n",
    "            mlflow.log_metric('Test_f1', log_test_f1)\n",
    "\n",
    "            mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classifiers\n",
    "run_classifier_models(X, y, 5, 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8dee898ae7ceba216e316f1e7e61d5a519768ade4905eb25ae05d4345cd77dde"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
