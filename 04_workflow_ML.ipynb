{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Using cached mlflow-2.1.1-py3-none-any.whl (16.7 MB)\n",
      "Collecting Flask<3\n",
      "  Using cached Flask-2.2.2-py3-none-any.whl (101 kB)\n",
      "Collecting alembic<2\n",
      "  Using cached alembic-1.9.1-py3-none-any.whl (210 kB)\n",
      "Collecting click<9,>=7.0\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Collecting cloudpickle<3\n",
      "  Using cached cloudpickle-2.2.0-py3-none-any.whl (25 kB)\n",
      "Collecting databricks-cli<1,>=0.8.7\n",
      "  Using cached databricks-cli-0.17.4.tar.gz (82 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting docker<7,>=4.0.0\n",
      "  Using cached docker-6.0.1-py3-none-any.whl (147 kB)\n",
      "Requirement already satisfied: entrypoints<1 in c:\\users\\4yousee\\appdata\\roaming\\python\\python311\\site-packages (from mlflow) (0.4)\n",
      "Collecting gitpython<4,>=2.1.0\n",
      "  Using cached GitPython-3.1.30-py3-none-any.whl (184 kB)\n",
      "Collecting importlib-metadata!=4.7.0,<6,>=3.7.0\n",
      "  Using cached importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
      "Collecting markdown<4,>=3.3\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Requirement already satisfied: matplotlib<4 in c:\\users\\4yousee\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow) (3.6.2)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\4yousee\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow) (1.24.1)\n",
      "Requirement already satisfied: packaging<23 in c:\\users\\4yousee\\appdata\\roaming\\python\\python311\\site-packages (from mlflow) (22.0)\n",
      "Requirement already satisfied: pandas<2 in c:\\users\\4yousee\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow) (1.5.2)\n",
      "Collecting protobuf<5,>=3.12.0\n",
      "  Using cached protobuf-4.21.12-cp310-abi3-win_amd64.whl (527 kB)\n",
      "Collecting pyarrow<11,>=4.0.0\n",
      "  Using cached pyarrow-10.0.1-cp311-cp311-win_amd64.whl (20.2 MB)\n",
      "Requirement already satisfied: pytz<2023 in c:\\users\\4yousee\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow) (2022.7)\n",
      "Collecting pyyaml<7,>=5.1\n",
      "  Using cached PyYAML-6.0-cp311-cp311-win_amd64.whl (143 kB)\n",
      "Collecting querystring-parser<2\n",
      "  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting requests<3,>=2.17.3\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: scikit-learn<2 in c:\\users\\4yousee\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow) (1.2.0)\n",
      "Requirement already satisfied: scipy<2 in c:\\users\\4yousee\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow) (1.9.3)\n",
      "Collecting shap<1,>=0.40\n",
      "  Using cached shap-0.41.0.tar.gz (380 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting sqlalchemy<2,>=1.4.0\n",
      "  Using cached SQLAlchemy-1.4.46-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "Collecting sqlparse<1,>=0.4.0\n",
      "  Using cached sqlparse-0.4.3-py3-none-any.whl (42 kB)\n",
      "Collecting Jinja2<4,>=3.0\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting waitress<3\n",
      "  Using cached waitress-2.1.2-py3-none-any.whl (57 kB)\n",
      "Collecting Mako\n",
      "  Using cached Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\4yousee\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click<9,>=7.0->mlflow) (0.4.6)\n",
      "Collecting pyjwt>=1.7.0\n",
      "  Using cached PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
      "Collecting oauthlib>=3.1.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting tabulate>=0.7.7\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\4yousee\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n",
      "Collecting urllib3>=1.26.0\n",
      "  Using cached urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Using cached websocket_client-1.4.2-py3-none-any.whl (55 kB)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\4yousee\\appdata\\roaming\\python\\python311\\site-packages (from docker<7,>=4.0.0->mlflow) (305)\n",
      "Collecting Werkzeug>=2.2.2\n",
      "  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.11.0-py3-none-any.whl (6.6 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.1.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\4yousee\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4->mlflow) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\4yousee\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4->mlflow) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\4yousee\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4->mlflow) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\4yousee\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\4yousee\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4->mlflow) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\4yousee\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4->mlflow) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\4yousee\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<4->mlflow) (2.8.2)\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\4yousee\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn<2->mlflow) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\4yousee\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn<2->mlflow) (3.1.0)\n",
      "Collecting tqdm>4.25.0\n",
      "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Collecting slicer==0.0.7\n",
      "  Using cached slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Collecting numba\n",
      "  Using cached numba-0.56.4.tar.gz (2.4 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [8 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\4YouSee\\AppData\\Local\\Temp\\pip-install-0ih1zujt\\numba_c5c2a55a989d4422ae22bee59ca59a67\\setup.py\", line 51, in <module>\n",
      "          _guard_py_ver()\n",
      "        File \"C:\\Users\\4YouSee\\AppData\\Local\\Temp\\pip-install-0ih1zujt\\numba_c5c2a55a989d4422ae22bee59ca59a67\\setup.py\", line 48, in _guard_py_ver\n",
      "          raise RuntimeError(msg.format(cur_py, min_py, max_py))\n",
      "      RuntimeError: Cannot install on Python version 3.11.1; only versions >=3.7,<3.11 are supported.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "%pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatetime\u001b[39;00m \u001b[39mimport\u001b[39;00m datetime\n\u001b[1;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmlflow\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m Normalizer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mlflow'"
     ]
    }
   ],
   "source": [
    "# import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import mlflow\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train set as a pandas dataframe\n",
    "train_set = pd.read_csv('data/train_set.csv')\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the features that we are going to use\n",
    "X = train_set.drop(['Churn'], axis=1)\n",
    "y = train_set['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. make pipelines to do the necessary transformations\n",
    "\n",
    "# 1.1 divide the qualitative and quantitative features\n",
    "quantitative_columns = selector(dtype_exclude=['object'])\n",
    "qualitative_columns = selector(dtype_include=['object'])\n",
    "\n",
    "quantitative_columns = quantitative_columns(X)\n",
    "qualitative_columns = qualitative_columns(X)\n",
    "\n",
    "# 1.2 apply the respective transformations with columntransformer method\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(drop='first'), qualitative_columns)],\n",
    "     remainder='passthrough')\n",
    "\n",
    "X_transformed = preprocessor.fit(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up MLFlow Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the mlflow experiment\n",
    "experiment_path = 'mlflow_experiments' # Defining the path of experiments in MLFlow\n",
    "experiment_name = '01_smart-pricing' # Defining the experiment name in MLFlow\n",
    "\n",
    "if(not(mlflow.get_experiment_by_name(experiment_name))): # If the experiment does not exist, create it\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "    \n",
    "mlflow.set_experiment(experiment_name) # Set the current experiment to register in MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting current date to save\n",
    "year = str(datetime.today().year)\n",
    "month = str(datetime.today().month)\n",
    "if len(month) == 1:\n",
    "    month = \"0\" + month\n",
    "day = str(datetime.today().day)\n",
    "if len(day) == 1:\n",
    "    day = \"0\" + day\n",
    "date = year + \"/\" + month + \"/\" + day "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifier_models(X, y, cv, scoring):\n",
    "    '''Função que treina os seguintes modelos de machine learning:\n",
    "    RandomForestClassifier, DecisionTreeClassifier, SGDClassifier, SVC,\n",
    "    LGBMClassifier, GaussianNB.\n",
    "    A função aplica a validação cruzada no conjunto de dados e retorna a média\n",
    "    da métrica selecionada no conjunto de treino e validação.\n",
    "    As únicas métricas ativas são Acurácia e F1 score.\n",
    "    Os experimentos com os modelos são acompanhados pelo MLflow.\n",
    "    \n",
    "    :param X: (dataframe or numpy array) \n",
    "    Dataframe ou array com o conjunto de variáveis independentes.\n",
    "    \n",
    "    :param y: (series or numpy array)\n",
    "    Coluna ou array com a variável dependente.\n",
    "    \n",
    "    :param cv: (int)\n",
    "    Determina a estratégia de divisão de validação cruzada.\n",
    "    \n",
    "    :param scoring: (str)\n",
    "    Estratégia para avaliar o desempenho do modelo de validação cruzada no conjunto de validação.\n",
    "    Deve ser passada entre aspas ao chamar a função.\n",
    "    '''\n",
    "    # 1. Instantiate the models\n",
    "    rf = RandomForestClassifier()\n",
    "    dt = DecisionTreeClassifier()\n",
    "    sgdc = SGDClassifier()\n",
    "    svc = SVC()\n",
    "    lgbm = LGBMClassifier()\n",
    "    gnb = GaussianNB()\n",
    "\n",
    "    # 2. train and evaluate the models\n",
    "    for model in (rf, dt, sgdc, svc, lgbm, gnb):\n",
    "        pipe = Pipeline(\n",
    "            steps=[('preprocessor', preprocessor),\n",
    "                   ('scaling', StandardScaler()),\n",
    "                   ('classifier', model)\n",
    "                  ]\n",
    "                )\n",
    "        scores = cross_validate(pipe, X, y, return_train_score=True,\n",
    "                                scoring=scoring, cv=cv)\n",
    "\n",
    "        # train and validation with accuracy\n",
    "        if scoring == 'accuracy':\n",
    "            log_train_acc = np.mean(scores['train_score'])\n",
    "            log_test_acc = np.mean(scores['test_score'])\n",
    "\n",
    "            # track the experiment with accuraccy\n",
    "            mlflow.start_run(run_name = date) \n",
    "            mlflow.log_param('Date', date) \n",
    "            mlflow.log_param('Features', X.columns)\n",
    "            mlflow.log_param('Pre-processing', preprocessor) \n",
    "            mlflow.log_param('ML model', pipe[2])\n",
    "\n",
    "            mlflow.log_metric('Train_acc', log_train_acc)\n",
    "            mlflow.log_metric('Test_acc', log_test_acc)\n",
    "\n",
    "            mlflow.end_run()\n",
    "\n",
    "        # train and validation with f1\n",
    "        if scoring == 'f1':\n",
    "            log_train_f1 = np.mean(scores['train_score'])\n",
    "            log_test_f1 = np.mean(scores['test_score'])\n",
    "\n",
    "            # track the experiment with f1 score\n",
    "            mlflow.start_run(run_name = date) \n",
    "            mlflow.log_param('Date', date) \n",
    "            mlflow.log_param('Features', X.columns)\n",
    "            mlflow.log_param('Pre-processing', preprocessor) \n",
    "            mlflow.log_param('ML model', pipe[2])\n",
    "\n",
    "            mlflow.log_metric('Train_f1', log_train_f1)\n",
    "            mlflow.log_metric('Test_f1', log_test_f1)\n",
    "\n",
    "            mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classifiers\n",
    "run_classifier_models(X, y, 5, 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mlflow ui"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49ef7ca59f3f09002a143d530e430c26b374a876365c25f5f40c472cf45f8ccd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
